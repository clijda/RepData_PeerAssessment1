y <- x-3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z*2=100
z*2+100
mySqrt <- sqrt(z-1)
mySqrt
myDiv <- z/mySqrt
myDiv
c(1, 2, 3, 4)+c(0,10)
c(1, 2, 3, 4)+c(0,10,100)
bye()
q()
library(swirl)
swirl()
1
swirl()
1:20
pi:10
15:17
15:1
?`:`
seq(1,20)
seq(0,10,by=0.5)
my_seq <- seq(5,30,length=30)
my_seq <- seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along=my_seq)
seq_along(my_seq)
rep(0, times=40)
rep(c(0,1,2), times=10)
rep(c(0,1,2), each=10)
num_vect <- c(0.5, 55, -10, 6)
tf <- num_vect[num_vect<1]
tf <- num_vect<1
tf
num_vect >=6
my_char <- c("My","name","is")
my_char
paste(my_char, collapse=" ")
my_name=c(my_char, "clijda")
my_name
paste(my_name, collapse=" ")
paste("Hello", "world", sep=" ")
paste("Hello", "world!", sep=" ")
paste(1:3, c("X","Y","Z"), sep="")
paste(LETTERS, 1:4, sep="-")
bye()
q()
my_url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
?download.file
download.file(my_url, "2006_microdata", method="curl")
q()
install.packages("xlsx")
?read.xlsx
??read.xlsx
swirl()
library(swirl)
swirl()
x <- c(44,NA,5,NA)
x*3
y <- rnorm(1000)
z <- rep(NA,1000)
mydata <- sample(c(y,z),100)
myData <- sample(c(y,z),100)
myNA <- is.na(myData)
myNA
myData==NA
sum(myNA)
myData
0/0
Inf-Inf
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y>0]
x[x>0]
x[!is.na(x) & x>0]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2,-10)]
x[-c(2,10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect,vect2)
vect["bar"]
vect[c("foo", "bar")]
myVector <- c[1:20]
myVector <- c(1:20)
myVector <- 1:20
myVector
dim(myVector)
length(myVector)
dim(myVector) <- c(4, 5)
dim(myVector)
attributes(myVector)
myVector
class(myVector)
myMatrix <- myVector
?matrix
myMatrix2 <- matrix(1;20,nrow=4,nvol=5)
myMatrix2 <- matrix(1;20,nrow=4,ncol=5)
myMatrix2 <- matrix(c(1:20),nrow=4,ncol=5)
identical(myMatrix,myMatrix2)
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(patients,myMatrix)
myData <- data.frame(patients, myMatrix)
myData
class(myData)
cnames <- c("patient", "age", "weight", "bp", "rating", "test")
colnames(myData) <- cnames
myData
q()
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
## Question 3
FileUrl<-"https://d396qusza40orc.cloudfront.net/getdata/data/DATA.gov_NGAP.xlsx"
download.file(FileUrl,"DATA.gov_NGAP.xlsx", method="auto",mode="wb")
library(xlsx)
Dat<-read.xlsx("DATA.gov_NGAP.xlsx",1,rowIndex=18:23, colIndex=7:15)
sum(dat$Zip*dat$Ext,na.rm=T)
## Question 4
library(XML)
XmlUrl<-"http://d396qusza40orc.cloudfront.net/getdata/data/restaurants.xml"
doc<-xmlTreeParse(XmlUrl,useInternal=T)
rootNode<-xmlRoot(doc)
zipcode<-xpathSApply(rootNode,"//zipcode",xmlValue)
zip<-zipcode[zipcode=="21231"]
length(zip)
## Question 5
FileUrl<-"http://d396qusza40orc.cloudfront.net/getdata/data/ss06pid.csv"
download.file(FileUrl,"ss06pid.csv",method="auto",mode="wb")
library(data.table)
DT<-fread("ss06pid.csv")
starttime<-proc.time()
DT[,mean(pwgtp15),by=SEX]
stoptime<-proc.time()
Exectime<-stoptime-starttime
Exectime
install.packages("xlsx")
library datasets
library(datasets)
data(mtcars)
s <- split(mtcars,mtcars$cyl)
apply(s,2,mean)
sapply(s, function(x) colMeans(x[,1:4],na.rm=TRUE))
data(iris)
s <- split(iris,iris$Species)
sapply(s, function(x) colMeans(x[,1:4],na.rm=TRUE))
data(mtcars)
lapply(mtcars, mean)
mean(mtcars$mpg, mtcars$cyl)
with(mtcars, tapply(mpg, cyl, mean))
apply(mtcars, 2, mean)
install.packages("KernSmooth")
load(KernSmooth)
library(KernSmooth)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
qplot(votes, rating, data = movies)
library(ggplot2)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + stats_smooth("loess")
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
install.packages("reshape2")
basicfeatures<-c(1,563:565)
cols<-c(meanfeatures,stdfeatures)
meanfeatures<-grep("mean",names(Data))
## read raw train and test data
X_train <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/train/X_train.txt", quote="\"")
X_test <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/test/X_test.txt", quote="\"")
## read subject and labels
subject_train <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/train/subject_train.txt", quote="\"")
y_train <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/train/y_train.txt", quote="\"")
subject_test <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/test/subject_test.txt", quote="\"")
y_test <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/test/y_test.txt", quote="\"")
activity_labels <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/activity_labels.txt", quote="\"")
names(activity_labels)<-c("labelid","activitylabel")
## read features of the data
features <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/features.txt", quote="\"")
features<-as.vector(features[,2])
# remove all weird characters ("(",")","-",",") and make lower case
features<-gsub("\\(","",features)
features<-gsub("\\)","",features)
features<-gsub("\\-","",features)
features<-gsub("\\,","",features)
features<-tolower(features)
names(X_train)<-features
names(X_test)<-features
## merge subjects, labels with training and testing data
X_train$type<-"train"
X_train<-cbind(X_train,subject_train)
names(X_train)[length(X_train)]<-"subject"
X_train<-cbind(X_train,y_train)
names(X_train)[length(X_train)]<-"labelid"
X_train<-merge(X_train,activity_labels,by.x="labelid",by.y="labelid")
X_test$type<-"test"
X_test<-cbind(X_test,subject_test)
names(X_test)[length(X_test)]<-"subject"
X_test<-cbind(X_test,y_test)
names(X_test)[length(X_test)]<-"labelid"
X_test<-merge(X_test,activity_labels,by.x="labelid",by.y="labelid")
## merge training and testing data
Data<-rbind(X_train,X_test)
## define only the needed columns
meanfeatures<-grep("mean",names(Data))
stdfeatures<-grep("std",names(Data))
basicfeatures<-c(1,563:565)
cols<-c(meanfeatures,stdfeatures)
## melt Data based on needed columns
## Datamelt is the tidy dataset containing mean and std
library(reshaoe2)
library(reshape2)
DataMelt<-melt(Data,id.vars=basicfeatures,measure.vars=cols)
AvgData<-dcast(Datamelt,activitylabel+subject~variable,mean)
AvgData<-dcast(DataMelt,activitylabel+subject~variable,mean)
AvgData[,1:6]
AvgData[,1:5]
TidyData<-Data[,c(meanfeatures,cols)]
View(TidyData)
str(TidyData)
# Merges the training and the test sets to create one data set.
# Extracts only the measurements on the mean and standard deviation for each measurement.
# Uses descriptive activity names to name the activities in the data set
# Appropriately labels the data set with descriptive activity names.
# Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
## read raw train and test data
X_train <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/train/X_train.txt", quote="\"")
X_test <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/test/X_test.txt", quote="\"")
## read subject and labels
subject_train <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/train/subject_train.txt", quote="\"")
y_train <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/train/y_train.txt", quote="\"")
subject_test <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/test/subject_test.txt", quote="\"")
y_test <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/test/y_test.txt", quote="\"")
activity_labels <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/activity_labels.txt", quote="\"")
names(activity_labels)<-c("labelid","activitylabel")
## read features of the data
features <- read.table("~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/features.txt", quote="\"")
features<-as.vector(features[,2])
# remove all weird characters ("(",")","-",",") and make lower case
features<-gsub("\\(","",features)
features<-gsub("\\)","",features)
features<-gsub("\\-","",features)
features<-gsub("\\,","",features)
features<-tolower(features)
names(X_train)<-features
names(X_test)<-features
## merge subjects, labels with training and testing data
X_train$type<-"train"
X_train<-cbind(X_train,subject_train)
names(X_train)[length(X_train)]<-"subject"
X_train<-cbind(X_train,y_train)
names(X_train)[length(X_train)]<-"labelid"
X_train<-merge(X_train,activity_labels,by.x="labelid",by.y="labelid")
X_test$type<-"test"
X_test<-cbind(X_test,subject_test)
names(X_test)[length(X_test)]<-"subject"
X_test<-cbind(X_test,y_test)
names(X_test)[length(X_test)]<-"labelid"
X_test<-merge(X_test,activity_labels,by.x="labelid",by.y="labelid")
## merge training and testing data
Data<-rbind(X_train,X_test)
## define only the needed columns
meanfeatures<-grep("mean",names(Data))
stdfeatures<-grep("std",names(Data))
basicfeatures<-c(1,563:565)
cols<-c(meanfeatures,stdfeatures)
## create tidy dataset by subsetting
TidyData<-Data[,c(meanfeatures,cols)]
## melt Data based on needed columns
## Datamelt is the tidy dataset containing mean and std variables and values
## AvgData is the second dataset which contains averages of all measurements per subject and activity
library(reshape2)
DataMelt<-melt(Data,id.vars=basicfeatures,measure.vars=cols)
AvgData<-dcast(DataMelt,activitylabel+subject~variable,mean)
## write Datasets to csv files
write.csv(TidyData,"~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/TidyData1.csv")
write.csv(AvgData,"~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/TidyData2.csv")
TidyData<-Data[,c(basicfeatures,cols)]
write.csv(TidyData,"~/Coursera/Getting and Cleaning Data/UCI HAR Dataset/TidyData1.csv")
View(TidyData)
View(AvgData)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
library(manipulate)
myHist <- function(mu){
hist(x,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean(w*(x - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
library(manipulate)
myHist <- function(mu){
hist(w*x,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean(w*(x - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
myHist <- function(mu){
hist(w*x,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean(w*(x - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
myHist <- function(mu){
hist(w*x,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean(w*(x - mu)^2)
text(150, 150, paste("mu = ", mu))
text(150, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
myHist <- function(mu){
hist(w*x,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean(w*(x - mu)^2)
text(10, 150, paste("mu = ", mu))
text(10, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
myHist <- function(mu){
hist(w*x,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean(w*(x - mu)^2)
text(10, 20, paste("mu = ", mu))
text(10, 10, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
library(manipulate)
myHist <- function(mu){
hist(w*x,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean(w*(x - mu)^2)
text(10, 20, paste("mu = ", mu))
text(10, 10, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
library(manipulate)
myHist <- function(mu){
hist(w*x,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean(w*(x - mu)^2)
text(1, 1, paste("mu = ", mu))
text(1, 1, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
library(manipulate)
myHist <- function(mu){
hist(w*x,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean(w*(x - mu)^2)
text(0.1, 1, paste("mu = ", mu))
text(1, 1, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
w*(x - 0.025)^2
mean(w*(x - 0.025)^2)
mean(w*(x - 1.077)^2)
mean(w*(x - 0.1471)^2)
mean(w*(x - 0.3)^2)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(I(x - mean(x))~ I(y - mean(y)) - 1)
lm(I(y - mean(y))~ I(x - mean(x)) - 1)
data(mtcars)
str(mtcars)
lm(I(y)~ I(x) - 1)
data(mtcars)
str(mtcars)
lm(I(mtcars$mpg)~ I(mtcars$wt) - 1)
lm(I(mtcars$mpg-mean(mtcars$mpg))~ I(mtcars$wt-mean(mtcars$wt)) - 1)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mean(x)
sd(x)
(x[1]-mean(x))/sd(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(I(y)~ I(x) - 1)
lm(I(x)~ I(y) - 1)
yn <- (y - mean(y))/sd(y)
xn <- (x - mean(x))/sd(x)
c(cor(y, x), cor(yn, xn), coef(lm(yn ~ xn))[2])
beta1 <- cor(y, x) * sd(y) / sd(x)
beta0 <- mean(y) - beta1 * mean(x)
rbind(c(beta0, beta1), coef(lm(y ~ x)))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta1 <- cor(x, y) * sd(x) / sd(y)
beta0 <- mean(x) - beta1 * mean(y)
rbind(c(beta0, beta1), coef(lm(x ~ y)))
install.packages("knitr")
library(knitr)
setwd("~/Coursera/Reproducible Research/RepData_PeerAssessment1")
install.packages("Rcurl")
remove.packages("RCurl")
install.packages("RCurl")
FileUrl <- "http://d396qusza40orc.cloudfront.net/repdata/data/activity.zip"
temp <- tempfile()
download.file(FileUrl,temp,method="auto",mode="wb")
con <- unz(temp,"activity.csv")
Data <- read.csv(con)
View(Data)
FileUrl <- "http://d396qusza40orc.cloudfront.net/repdata/data/activity.zip"
temp <- tempfile()
download.file(FileUrl,temp,method="auto",mode="wb")
con <- unz(temp,"activity.csv")
Data <- read.csv(con)
FileUrl <- "http://d396qusza40orc.cloudfront.net/repdata/data/activity.zip"
temp <- tempfile()
download.file(FileUrl,temp,method="auto",mode="wb")
con <- unz(temp,"activity.csv")
Data <- read.csv(con)
Data <- read.csv(con, stringsAsFactors=FALSE)
FileUrl <- "http://d396qusza40orc.cloudfront.net/repdata/data/activity.zip"
temp <- tempfile()
download.file(FileUrl,temp,method="auto",mode="wb")
con <- unz(temp,"activity.csv")
Data <- read.csv(con, stringsAsFactors=FALSE)
Data$datetime <- strptime(paste(Data$date,Data$interval),"%Y-%m-%d %S")
View(Data)
View(Data)
Data$steps <- as.numeric(Data$steps)
View(Data)
Data$datetime <- strptime(paste(Data$date,Data$interval),"%Y-%m-%d %H%M")
View(Data)
Data$interval1 <- as.character(Data$interval,digits=4)
View(Data)
Data$interval1 <- format(Data$interval,"0000")
Data$interval1 <- sprintf("%04d", Data$interval)
View(Data)
Data$interval <- sprintf("%04d", Data$interval)
Data$datetime <- strptime(paste(Data$date,Data$interval),"%Y-%m-%d %S")
Data$steps <- as.numeric(Data$steps)
View(Data)
Data$datetime <- strptime(paste(Data$date,Data$interval),"%Y-%m-%d %H%S")
View(Data)
Data$datetime <- strptime(paste(Data$date,Data$interval),"%Y-%m-%d %H%M")
View(Data)
hist(Data$steps)
hist(Data$steps, breaks=12)
hist(Data$steps, breaks=24)
hist(Data$steps, breaks=48)
hist(Data$steps, breaks=100)
summary(Data)
install.packages("ggplot2")
library(ggplot2)
qplot(Data$datetime,Data$steps)
x<-tapply(Data$steps,as.factor(Data$interval),mean)
x
x<-tapply(Data$steps,as.factor(Data$interval),mean,na.rm=TRUE)
x
View(Data)
qplot(x$interval,x$steps,data=x, geom="line")
install.packages("plyr")
library(plyr)
